# -*- coding: utf-8 -*-
"""Copy of 2_深度學習4_cks

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jGLaIdJJkRrtv2CFT7MlDGPcVh207fEv
"""

# check GPU infomation
!nvidia-smi

# check google drive mounting
import os
if not os.path.isdir('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')
else:
    print("Google drive is mounted !")

"""## ~匯入所有需要的套件模組"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")  # 忽略所有 Warning

# tensorflow.keras
# %tensorflow_version 2.x
import tensorflow as tf
print("Tensorflow version =", tf.__version__)
from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras import optimizers, layers, callbacks
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras import backend as K

"""# 準備資料集

## 1-讀取資料集
"""

# 自定義來源路徑
file = '/content/drive/MyDrive/python 深度學習/Colab Notebooks4/dataset 4 30.csv'
df = pd.read_csv(file, index_col=0)  # 將第0欄作為 index
df

# 轉成 numpy array
data = df.values
data.shape

"""## 2-資料前處理

### 定義資料產生器
以產生時間序列樣本 example (X) 、及其目標 target y
- data - 原始的浮點數資料陣列
- lookback - 輸入的資料應回溯多少個時間點
- delay - 目標 y 應該在未來多少個時間點
- min_index - 欲使用資料陣列的最小索引值
- max_index - 欲使用資料陣列的最大索引值
- shuffle - 是否按照時間順序使用樣本，或打亂樣本
- batch_size - 每批次的樣本數量
"""

# 定義 generator
def generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=1):
    if max_index is None:
        max_index = len(data) - delay - 1
    i = min_index  # 資料起始 index

    # 一直循環
    while True:
        # 產生 批次的rows (資料時間點)
        if shuffle:
            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)
        else:
            if (i > max_index): 
                i = min_index  # reset 資料起始 index
            rows = np.arange(i, min(i + batch_size, max_index + 1))
            i = i + len(rows)  # 下一個起點

        # 產生批次全為0的 samples 和 targets
        samples = np.zeros((len(rows), lookback, data.shape[-1]), dtype=np.float32)
        targets = np.zeros((len(rows), ), dtype=np.float32)
        # 逐筆填入資料
        for j, row in enumerate(rows):
            indexes = range(rows[j] - lookback, rows[j])
            samples[j] = data[indexes]
            try:
                targets[j] = data[rows[j] + delay][0]  # <-- [0] 為預測的特徵欄位index(台灣新增人數) (自行修改)
            except IndexError:
                # test data 會找不到對應的 y
                targets[j] = np.nan

        # 在 samples 加上最後一軸 作為色彩channel --> shape=(8, 25, 1)  # 1 為單色channel之意
        samples = samples[:, :, :, np.newaxis]  # shape=(batch, lookback, features, 1)

        # 依呼叫產生一批 samples 和 targets
        yield samples, targets

"""### 建立 訓練資料產生器、驗證資料產生器"""

# 定義變數
lookback = 9
delay = 7
batch_size = 4

print("可訓練資料 max_index =", len(data) - delay - 1)
print("可訓練資料筆數 :", len(data) - delay - lookback)

# 訓練資料產生器
min_index = 0 + lookback  # 第8筆開始，可使用回溯8天的資料
max_index = 79  # 前70筆作訓練用
train_steps = int(np.ceil((max_index - min_index + 1)/batch_size))
print("train_steps per epoch:", train_steps)

train_gen = generator(data=data, 
                      lookback=lookback, 
                      delay=delay, 
                      min_index=min_index, 
                      max_index=max_index, 
                      shuffle=True,  # 訓練是否洗牌
                      batch_size=batch_size)

# 驗證資料產生器
min_index = 80
max_index = 95  # 為可訓練資料 max_index
valid_steps = int(np.ceil((max_index - min_index + 1)/1))
print("valid_steps per epoch:", valid_steps)

valid_gen = generator(data=data, 
                      lookback=lookback, 
                      delay=delay, 
                      min_index=min_index, 
                      max_index=max_index, 
                      shuffle=False,  # 驗證不必要洗牌
                      batch_size=1)

# 測試資料產生器
for k in range(train_steps):
    samples, targets = next(train_gen)
    print(f"batch {k} samples/targets shape :", samples.shape, targets.shape,  "targets =", targets)
for k in range(valid_steps):
    samples, targets = next(valid_gen)
    print(f"batch {k} samples/targets shape :", samples.shape, targets.shape,  "targets =", targets)

# 以影像方式呈現 sample
fig = plt.figure(figsize=(14, 4))
fig.suptitle('This is a transposed view of sample', fontsize=16)

for k in range(valid_steps):
    samples, targets = next(valid_gen)  # 從 generater 取 sample
    fig.add_subplot(1, valid_steps, k+1)
    plt.title(targets)
    plt.axis('off')
    plt.imshow(samples.reshape(samples.shape[1:3]).T, 
            #    cmap='gray', 
               )
plt.show()
print("Original shape = (batch, lookback, features, monocolor) =", samples.shape)

"""# 設計模型 modeling

functional-API : 
https://keras.io/models/model/
(嘗試不同的設計)

## -模型設計 - CNN + RNN
https://keras.io/layers/core/

https://keras.io/activations/
"""

# 清空所有暫存
K.clear_session()

# 使用函數式建模 fuctional-API
inputs = layers.Input((lookback, data.shape[-1], 1))  # (時間空間的維度, 輸入特徵空間的維度, 單色channel) 視為一個黑白圖片
cx = layers.Conv2D(filters=6, kernel_size=(3,1), strides=1, padding='valid', activation='relu')(inputs)
cx = layers.Conv2D(filters=4, kernel_size=(3,1), strides=1, padding='valid', activation='relu')(cx)
cx = layers.Conv2D(filters=2, kernel_size=(3,1), strides=1, padding='valid', activation='relu')(cx)
cx = layers.Conv2D(filters=1, kernel_size=(1,1), strides=1, padding='valid', activation='relu')(cx)
cx = layers.Flatten()(cx)
cx = layers.Dropout(0.5)(cx)
cx = layers.Dense(8, activation='sigmoid', kernel_initializer='normal')(cx)

rnn_inp = layers.Reshape((lookback, data.shape[-1]))(inputs)  # <-- 分支RNN輸入 (時間空間的維度, 輸入特徵空間的維度)
rx = layers.GRU(8, dropout=0.15, return_sequences=True)(rnn_inp)
rx = layers.GRU(8, dropout=0.15, return_sequences=True)(rx)
rx = layers.GRU(8, dropout=0.15, return_sequences=True)(rx)
rx = layers.GRU(8, dropout=0.1, kernel_initializer='normal')(rx)

concat = layers.Concatenate()([cx, rx])  # <-- 串接隱藏層
outputs = layers.Dense(1, kernel_initializer='normal')(concat)

model = Model(inputs=inputs, outputs=outputs)

model._name = 'AZXCVnormal_R8888O15normal_D1normal'
model.summary()

"""## -模型圖"""

# plot model
model_dir = "model/{}".format(model.name)  # 自定義模型儲存的目錄
os.makedirs(model_dir, exist_ok=True)
plot_model(model, to_file=model_dir + "/model_plot.png".format(model.name), show_shapes=True, dpi=60)

"""## -編譯模型
- https://keras.io/losses/
- https://keras.io/optimizers/
- https://keras.io/metrics/
"""

# compile model
optimizer = optimizers.RMSprop(learning_rate=0.0008)  # default=0.001
model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])

"""# 訓練模型 training

## -回調函數
https://www.tensorflow.org/api_docs/python/tf/keras/callbacks
"""

# Callbacks
mc = callbacks.ModelCheckpoint(filepath=model_dir + '/best_model.h5', monitor='val_mae', mode='min', save_best_only=True)
rl = callbacks.ReduceLROnPlateau(monitor='val_mae', mode='min', factor=0.5, patience=5)
es = callbacks.EarlyStopping(monitor='val_mae', mode='min', patience=30)
tb = callbacks.TensorBoard(log_dir='logs/{}'.format(model.name))
callbacks_list = [mc, rl, es, tb]

"""## -開始訓練模型"""

# start training
EPOCHS = 100
history = model.fit(train_gen, 
                    steps_per_epoch=train_steps*10, 
                    epochs=EPOCHS, 
                    validation_data=valid_gen, 
                    validation_steps=valid_steps, 
                    callbacks=callbacks_list)

"""## -訓練曲線"""

# Training history visualization
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6,12))

# Plot training & validation accuracy values
ax1.plot(history.history['mae'])
ax1.plot(history.history['val_mae'])
ax1.set_title('Mean Absolute Error')
ax1.set(ylabel='Mean Absolute Error', xlabel='Epoch')
ax1.legend(['Train', 'Valid'], loc='upper right')

# Plot training & validation loss values
ax2.plot(history.history['loss'])
ax2.plot(history.history['val_loss'])
ax2.set_title('Model loss')
ax2.set(ylabel='Loss', xlabel='Epoch')
ax2.legend(['Train', 'Valid'], loc='upper right')

plt.savefig(model_dir + '/train_history.png', dpi=72)  # <-- save plot
plt.show()

"""## TensorBoard
https://www.tensorflow.org/tensorboard/get_started
"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard
# 指定 logs 的路徑
# %tensorboard --logdir 'logs'

# 刪除 logs 資料夾，清除所有記錄 (小心使用)
# !rm -rf 'logs'

"""# 模型評估 evaluation
https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics
"""

# restore model
# 選一個比較好的模型做評估
model_dir = '/content/model/AZXCVnormal_R8888O15normal_D1normal'  # <-- 指定模型名稱目錄
model = load_model(model_dir + '/best_model.h5')
model.trainable = False  # freeze all layers for inference

y_true = np.array([ next(valid_gen)[1] for i in range(valid_steps) ])
y_pred = model.predict(valid_gen,
                       steps=valid_steps, 
                       verbose=1)
# 乘回來y特徵工程時的倍數
y_true = y_true * 20
y_pred = y_pred.reshape(-1,) * 20

print("y_true shape:", y_true.shape, "\ty_pred shape:", y_pred.shape)
print("y_pred =", y_pred)

from sklearn.metrics import median_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

print("Median Absolute Error (MAE) =", median_absolute_error(y_true, y_pred))
print("Root Mean Square Error (RMSE) =", mean_squared_error(y_true, y_pred, squared=False))
print("R² score =", r2_score(y_true, y_pred))

"""# 模型預測 prediction

## -下載交卷範本
"""

# 下載交卷範本
!wget 'https://storage.googleapis.com/meso_patho/submission_sample.csv'
submit_df = pd.read_csv('submission_sample.csv')
submit_df

"""## [第一區段預測]
04/15 - 04/21
"""

# 測試資料產生器
min_index = df.index.get_loc('2020-04-08')  # 取得起始日期-7的 index (-delay)
max_index = df.index.get_loc('2020-04-14')  # 取得結束日期-7的 index (-delay)
test_steps = int(np.ceil((max_index - min_index + 1)/1))
print("test_steps per epoch:", test_steps)

test_gen = generator(data=data, 
                     lookback=lookback, 
                     delay=delay, 
                     min_index=min_index, 
                     max_index=max_index, 
                     shuffle=False,  # 依定要按時序預測
                     batch_size=1)

for k in range(test_steps):
    samples, targets = next(test_gen)
    print(f"batch {k} samples/targets shape :", samples.shape, targets.shape,  "targets =", targets)

"""## --預測"""

# prediction
y_pred_1 = model.predict(test_gen, 
                       steps=test_steps, 
                       verbose=1)
y_pred_1 = y_pred_1.reshape(-1,)  # flatten array to 1D

print("Predicted result =", y_pred_1)

"""## --數據後處理"""

y_pred = []
y_pred.extend(y_pred_1 * 20)  # 乘回來y特徵工程時的倍數
y_pred

# ground truth
(df.loc['2020-04-15':'2020-04-21']['TW'].values * 20).tolist()

"""## [第二區段預測]
05/06 - 05/12

(05/05 的資料有了以後，才能正常預測到 05/12, 才能正常執行以下程式碼)

(練習時，可以改變日期範圍，用今天前7天的資料做預測)
"""

# 測試資料產生器
min_index = df.index.get_loc('2020-04-27')  # 取得起始日期-7的 index (-delay)
max_index = df.index.get_loc('2020-05-03')  # 取得結束日期-7的 index (-delay)
test_steps = int(np.ceil((max_index - min_index + 1)/1))
print("test_steps per epoch:", test_steps)

test_gen = generator(data=data, 
                     lookback=lookback, 
                     delay=delay, 
                     min_index=min_index, 
                     max_index=max_index, 
                     shuffle=False,  # 依定要按時序預測
                     batch_size=1)

for k in range(test_steps):
    samples, targets = next(test_gen)
    print(f"batch {k} samples/targets shape :", samples.shape, targets.shape,  "targets =", targets)

"""## --預測"""

# prediction
y_pred_2 = model.predict(test_gen, 
                       steps=test_steps, 
                       verbose=1)
y_pred_2 = y_pred_2.reshape(-1,)  # flatten array to 1D

print("Predicted result =", y_pred_2)

"""## --數據後處理
將每日新增人數 轉為 累計人數
"""

y_pred.extend(y_pred_2 * 20)  # 乘回來y特徵工程時的倍數
y_pred = [ y if y>0 else 0.0 for y in y_pred ]  # 如果小於零，輸出零
y_pred

"""# 提交答案 submission

## -填入答案
"""

submit_df['Confirm_cases'] = y_pred
submit_df

"""## -另存檔案"""

# save without index column
submit_df.to_csv('my_submission.csv', index=False)

"""## -下載提交檔"""

from google.colab import files
files.download('my_submission.csv')

