# -*- coding: utf-8 -*-
"""dataset prepare

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vwnR9BYwa4ScuQ5X1uBYIHkvkqa-z-GG
"""

# check google drive mounting
import os
if not os.path.isdir('/content/drive'):
    from google.colab import drive
    drive.mount('/content/drive')
else:
    print("Google drive is mounted !")

from google.colab import drive
drive.mount('/content/drive')

"""## 匯入所有需要的套件模組"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")  # 忽略所有 Warning
import datetime

"""# 資料下載

## 1-下載 CSSE COVID-19 Dataset
https://github.com/CSSEGISandData/COVID-19
(下載的位置為 /content/COVID-19)
"""

# 從 github 下載資料
!git clone 'https://github.com/CSSEGISandData/COVID-19'

"""### 讀取CSSE最新時間累積資料"""

# Read global confirm data
CONFIRM_FILE = '/content/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'
confirm_df = pd.read_csv(CONFIRM_FILE)
confirm_df

"""### 擷取台灣資料成為新的 DataFrame"""

my_confirm_df = confirm_df.loc[confirm_df['Country/Region']=='Taiwan*']  # 選取台灣資料
my_confirm_df = my_confirm_df.iloc[:, 4:]  # 移除前4欄
my_confirm_df = my_confirm_df.transpose()  # 轉置, 日期成為index
# 重新命名欄位
column_name = my_confirm_df.columns
my_confirm_df = my_confirm_df.rename(columns={column_name[0]: "TW"})
my_confirm_df

# TW 改為 每日新增人數
my_confirm_df['TW'] = my_confirm_df['TW'].diff().fillna(0)
my_confirm_df

"""### 加入其他特徵欄位"""

# 全球每日增加總數
global_new_series = confirm_df.iloc[:,4:].sum().diff().fillna(0)
my_confirm_df['global'] = global_new_series
my_confirm_df

# 各國每日增加人數
# 桃機定期客機入境  https://www.taoyuan-airport.com/main_ch/flight_timetable.aspx?uid=160&pid=12&PlaneType=PA&mc=sys010106
departure_list = ['Thailand', 'Japan', 'Hong Kong', 'Korea, South', 'Philippines', 'US', 'Canada', 'Australia', 'Austria', 
                  'Vietnam', 'Germany', 'Netherlands', 'France', 'Malaysia', 'Macau', 'Cambodia', 'Russia', 
                  'United Arab Emirates', 'United Kingdom', 'Turkey', 'Singapore', 'Indonesia']
# 依序加入國家總合人數(一些國家有多個地區，加總起來算一個特徵)
for C in departure_list:
    if (confirm_df['Province/State']==C).any():  # 地區
        my_confirm_df[C] = confirm_df.loc[confirm_df['Province/State']==C].iloc[:, 4:].sum().diff().fillna(0)
    elif (confirm_df['Country/Region']==C).any():  # 國家
        my_confirm_df[C] = confirm_df.loc[confirm_df['Country/Region']==C].iloc[:, 4:].sum().diff().fillna(0)
    else:
        print('[error] Cannot find country:', C)
my_confirm_df.columns

"""### 處理index的日期格式為 標準時間物件
(為了不同資料合併的依據，有相同的 index 方便資料對齊)
"""

my_confirm_df.index = pd.to_datetime(my_confirm_df.index, format='%m/%d/%y')
print("修改後的 index 為:", my_confirm_df.index)

my_confirm_df.tail()

"""## 2-桃機 航班運量整點人數預報表
https://www.taoyuanairport.com.tw/main_ch/flight/Fos.aspx?uid=1815&pid=23

### 讀取 2020年1月、2月 入境人數舊資料
"""

# 自行修正檔案路徑
entry_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/桃機入境人數_2020年_1月_2月.csv.csv 的副本', index_col=0)
entry_df.head(2)

# 修改 date 字串
entry_df.index = entry_df.index.str.replace('/','_')
entry_df.head(2)

"""### 用 pandas 讀取桃機網頁表格
https://www.taoyuanairport.com.tw/main_ch/flight/Fos.aspx?uid=1815&pid=23
"""

url = 'https://www.taoyuanairport.com.tw/main_ch/flight/Fos.aspx?uid=1815&pid=23'
html_df = pd.read_html(url)[0]
html_df.head()

"""### 產生 '每小時更新版' 下載連結"""

# 最後一日的資料 是哪一天
file_name_arr = html_df['每小時更新版'].dropna().to_numpy()
print("最新一日的資料:", file_name_arr[0])
last_date_str = file_name_arr[0].split('_航班')[0]
print("最新一日是:", last_date_str)

# 2020/03/01 為此資料庫的起始點
start = datetime.datetime.strptime("2020_03_01", "%Y_%m_%d")
end = datetime.datetime.strptime(last_date_str, "%Y_%m_%d")
print("start_date:", start, type(start))
print("end_date:", end, type(end))

# 產生區間日期 list
date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days + 1)]

# 產生區間日期的下載連結
# '每小時更新版' file link example: https://www.taoyuanairport.com.tw/upload/fos/2020_04_08_update.xls
url = 'https://www.taoyuanairport.com.tw/upload/fos/'
file_link_list = []
for date in date_generated:
    file_link_list.append(url + date.strftime("%Y_%m_%d") + '_update.xls')
file_link_list

"""### 用 pandas 讀取 excel 檔案"""

xls_df = pd.read_excel(file_link_list[0])
xls_df

"""### 抓 '總人數' 的資料"""

# row to numpy array
total_count_arr = xls_df.loc[xls_df.iloc[:, 0] == '總人數'].values
print(total_count_arr)
# Get data [總計入境]
entry_count = total_count_arr[0][1]
print("總計入境 =", entry_count)

# 人數資料寫入 entry_df
entry_df.loc['2020_03_01'] = entry_count
entry_df.tail(2)

"""### 處理所有 xls 資料"""

data_list = []

for file_link in file_link_list:  # 從2020-03-01開始處理
    # 讀取 xls
    xls_df = pd.read_excel(file_link)
    # Get data [總計入境]
    total_count_arr = xls_df.loc[xls_df.iloc[:, 0] == '總人數'].values
    entry_count = total_count_arr[0][1]

    # 從檔案連結取得日期字串
    date = file_link.split('/')[-1].replace('_update.xls','')
    # append data into entry_df
    entry_df.loc[date] = entry_count

    del xls_df, total_count_arr, entry_count

entry_df

"""### 處理日期格式成為 index"""

# index to datetime
entry_df.index = pd.to_datetime(entry_df.index, format='%Y_%m_%d')
entry_df.info()  # 檢查是否有缺值 null

# 另存資料 csv
entry_df.to_csv('/content/drive/My Drive/Colab Notebooks/桃機入境.csv')

"""## 3-其他來源資料

可以參考 https://docs.google.com/spreadsheets/d/1Kp5IC5IEI2ffaOSZY1daYoi2u50bjUHJW-IgfHoEq8o/edit#gid=0

"0_台灣輔助資料.ipynb"
"""





"""# 資料整合
https://ithelp.ithome.com.tw/articles/10200433
"""

# 聯集會有對不上的部分，會是空值
dataset_df = pd.merge(my_confirm_df, entry_df,  
                    left_index=True, right_index=True, how="outer")
dataset_df

# 手動補上今天的最新資料
# https://www.cdc.gov.tw/
# https://who.sprinklr.com/
dataset_df.loc['2020-05-06', 'TW'] = 0
dataset_df.loc['2020-05-06', 'global'] = dataset_df.loc['2020-05-05', 'global'] + 86030

# # 補上其他國家新增例 (假設與前一天相同)
dataset_df.loc['2020-05-06', 'Thailand':'Indonesia'] = dataset_df.loc['2020-05-05', 'Thailand':'Indonesia']

dataset_df.tail()

"""## 1-處理空值
(依自己的假設補空值)
"""

# 將 entry_ 空值補上
dataset_df = dataset_df.fillna(0)  # 空值補0
dataset_df

# 指定資料範圍： 刪除多餘的資料記錄 (捨棄'2020-01-20'之前，和隔天的資料)
dataset_df = dataset_df.loc['2020-01-20':'2020-05-06']
dataset_df

"""## 2-特徵工程"""

# 取得各特徵的描述性統計
dataset_df.describe()

# 調整最大值為1 的欄位
col_name_arr = dataset_df.loc[:, 'global':'Indonesia'].columns.values
print('col_name_arr =', col_name_arr)
for C in col_name_arr:
    dataset_df[C] = dataset_df[C] / dataset_df[C].max()
dataset_df.describe()

# 單獨調整 其他部分 數據範圍
dataset_df['TW'] = dataset_df['TW'] / 20  # 最後需要乘回來
dataset_df['TPE entry'] = dataset_df['TPE entry'] / 40000
dataset_df.describe()

# 特徵矩陣 feature matrix using Pearson Correlation
plt.figure(figsize=(12,10))
cor = dataset_df.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

"""## 3-產生目標 y值
(RNN CNN 用不到)
"""

# 以預測一週後的台灣新增人數為目標
dataset_df['y'] = dataset_df['TW_new'].shift(periods=-7)
dataset_df

"""# 另存訓練資料集"""

# 自訂儲存路徑
path = '/content/drive/My Drive/1082_醫療深度學習Python實作/1_9 weeks online course/0507_deep learning 5'
dataset_df.to_csv(path + '/dataset.csv')

